{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py as hpy\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=hpy.File('train_signs.h5','r')\n",
    "test_dataset=hpy.File('test_signs.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['list_classes', 'test_set_x', 'test_set_y']>\n",
      "TensorSpec(shape=(64, 64, 3), dtype=tf.uint8, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.keys())\n",
    "x_train=tf.data.Dataset.from_tensor_slices(train_dataset['train_set_x'])\n",
    "y_train=tf.data.Dataset.from_tensor_slices(train_dataset['train_set_y'])\n",
    "x_test=tf.data.Dataset.from_tensor_slices(test_dataset['test_set_x'])\n",
    "y_test=tf.data.Dataset.from_tensor_slices(test_dataset['test_set_y'])\n",
    "\n",
    "print(x_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[231 224 216]\n",
      "  [232 224 216]\n",
      "  [232 225 217]\n",
      "  ...\n",
      "  [226 218 210]\n",
      "  [226 217 209]\n",
      "  [225 216 208]]\n",
      "\n",
      " [[231 224 215]\n",
      "  [232 224 215]\n",
      "  [231 225 216]\n",
      "  ...\n",
      "  [226 218 210]\n",
      "  [225 217 209]\n",
      "  [224 216 208]]\n",
      "\n",
      " [[231 223 215]\n",
      "  [231 224 215]\n",
      "  [231 224 216]\n",
      "  ...\n",
      "  [225 218 209]\n",
      "  [225 218 209]\n",
      "  [224 217 208]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[201 193 185]\n",
      "  [201 193 185]\n",
      "  [201 193 185]\n",
      "  ...\n",
      "  [216 204 196]\n",
      "  [217 204 195]\n",
      "  [216 204 193]]\n",
      "\n",
      " [[201 193 185]\n",
      "  [201 193 185]\n",
      "  [201 192 185]\n",
      "  ...\n",
      "  [216 204 195]\n",
      "  [217 204 195]\n",
      "  [217 204 193]]\n",
      "\n",
      " [[200 192 185]\n",
      "  [200 193 185]\n",
      "  [200 192 184]\n",
      "  ...\n",
      "  [217 204 195]\n",
      "  [218 204 195]\n",
      "  [217 204 193]]], shape=(64, 64, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "unique_labels=set()\n",
    "for element in y_train:\n",
    "    unique_labels.add(element.numpy())\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image):\n",
    "    '''\n",
    "    transform an image into a tensor of shape (64*64*3,) and normalize its components\n",
    "\n",
    "    '''\n",
    "    image=tf.cast(image,tf.float32)/255.0\n",
    "    image=tf.reshape(image,[-1])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(12288,), dtype=tf.float32, name=None)\n"
     ]
    }
   ],
   "source": [
    "new_train=x_train.map(normalize)\n",
    "new_test=x_test.map(normalize)\n",
    "\n",
    "print(new_test.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.8901961  0.8627451  0.8392157  ... 0.8156863  0.81960785 0.81960785], shape=(12288,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(new_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]], shape=(4, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "def linear_function():\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    X=tf.constant(np.random.randn(3,1),name='x')\n",
    "\n",
    "    W=tf.constant(np.random.randn(4,3),name='W')\n",
    "    \n",
    "    b=tf.constant(np.random.randn(4,1),name='b')\n",
    "\n",
    "    Y=tf.add(tf.matmul(W,X),b)\n",
    "    \n",
    "    return Y\n",
    "\n",
    "print(linear_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "tf.Tensor(0.5, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    z=tf.cast(z,tf.float32)\n",
    "    s=tf.keras.activations.sigmoid(z)\n",
    "\n",
    "    return s\n",
    "\n",
    "result=sigmoid(0)\n",
    "print(result.dtype)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(label,depth=6):\n",
    "    '''\n",
    "    label= int, categorical labels\n",
    "    depth= int, bumber of different classes that label can take\n",
    "    '''\n",
    "    one_hot=tf.one_hot(label,depth,axis=0)\n",
    "    one_hot=tf.reshape(one_hot,[-1])\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 0. 0. 0. 0. 0.], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "new_y_test=y_test.map(one_hot_matrix)\n",
    "new_y_train=y_train.map(one_hot_matrix)\n",
    "\n",
    "print(next(iter(new_y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    '''\n",
    "    Shapes are:\n",
    "    W1:[25,12288]\n",
    "    b1:[25,1]\n",
    "    W2:[12,25]\n",
    "    b2:[12,1]\n",
    "    W3:[6,12]\n",
    "    b3:[6,1]\n",
    "\n",
    "    returns parameters\n",
    "    '''\n",
    "    initializer=tf.keras.initializers.GlorotNormal(seed=1)\n",
    "\n",
    "    W1=tf.Variable(initializer(shape=(25,12288)))\n",
    "    b1=tf.Variable(initializer(shape=(25,1)))\n",
    "    W2=tf.Variable(initializer(shape=(12,25)))\n",
    "    b2=tf.Variable(initializer(shape=(12,1)))\n",
    "    W3=tf.Variable(initializer(shape=(6,12)))\n",
    "    b3=tf.Variable(initializer(shape=(6,1)))\n",
    "\n",
    "    parameters={'W1':W1,\n",
    "                'b1':b1,\n",
    "                'W2':W2,\n",
    "                'b2':b2,\n",
    "                'W3':W3,\n",
    "                'b3':b3}\n",
    "    \n",
    "\n",
    "    return parameters\n",
    "\n",
    "parameters=initialize_parameters()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    '''\n",
    "    X- input dataset placeholder, of shape (input size, number of examples)\n",
    "\n",
    "    returns\n",
    "    Z3-- outpit of the last linear unit\n",
    "    '''\n",
    "    W1=parameters['W1']\n",
    "    b1=parameters['b1']\n",
    "    W2=parameters['W2']\n",
    "    b2=parameters['b2']\n",
    "    W3=parameters['W3']\n",
    "    b3=parameters['b3']\n",
    "\n",
    "    Z1=tf.math.add(tf.linalg.matmul(W1,X),b1)\n",
    "    A1_0=tf.keras.activations.relu(Z1[:,:16])\n",
    "    A1_1=tf.keras.activations.sigmoid(Z1[:,16:])\n",
    "\n",
    "    A1_2=tf.concat((A1_0,A1_1),axis=1)\n",
    "    # print(A1_2.shape)\n",
    "    \n",
    "    # A1=tf.keras.activations.relu(Z1)\n",
    "    Z2=tf.math.add(tf.linalg.matmul(W2,A1_2),b2)\n",
    "    A2=tf.keras.activations.relu(Z2)\n",
    "    Z3=tf.math.add(tf.linalg.matmul(W3,A2),b3)\n",
    "\n",
    "    return Z3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(logits,labels):\n",
    "\n",
    "    cost=tf.reduce_sum(tf.keras.metrics.categorical_crossentropy(tf.transpose(labels),tf.transpose(logits),from_logits=True))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 10 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    # Initialize your parameters\n",
    "    #(1 line)\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    # The CategoricalAccuracy will track the accuracy for this multiclass problem\n",
    "    test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    dataset = tf.data.Dataset.zip((X_train, Y_train))\n",
    "    test_dataset = tf.data.Dataset.zip((X_test, Y_test))\n",
    "    \n",
    "    # We can get the number of elements of a dataset using the cardinality method\n",
    "    m = dataset.cardinality().numpy()\n",
    "    \n",
    "    minibatches = dataset.batch(minibatch_size).prefetch(8)\n",
    "    test_minibatches = test_dataset.batch(minibatch_size).prefetch(8)\n",
    "    #X_train = X_train.batch(minibatch_size, drop_remainder=True).prefetch(8)# <<< extra step    \n",
    "    #Y_train = Y_train.batch(minibatch_size, drop_remainder=True).prefetch(8) # loads memory faster \n",
    "\n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        epoch_cost = 0.\n",
    "        \n",
    "        #We need to reset object to start measuring from 0 the accuracy each epoch\n",
    "        train_accuracy.reset_states()\n",
    "        \n",
    "        for (minibatch_X, minibatch_Y) in minibatches:\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                # 1. predict\n",
    "                Z3 = forward_propagation(tf.transpose(minibatch_X), parameters)\n",
    "\n",
    "                # 2. loss\n",
    "                minibatch_cost = compute_cost(Z3, tf.transpose(minibatch_Y))\n",
    "\n",
    "            # We acumulate the accuracy of all the batches\n",
    "            train_accuracy.update_state(tf.transpose(Z3), minibatch_Y)\n",
    "            \n",
    "            trainable_variables = [W1, b1, W2, b2, W3, b3]\n",
    "            grads = tape.gradient(minibatch_cost, trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "            epoch_cost += minibatch_cost\n",
    "        \n",
    "        # We divide the epoch cost over the number of samples\n",
    "        epoch_cost /= m\n",
    "\n",
    "        # Print the cost every 10 epochs\n",
    "        if print_cost == True and epoch % 10 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            print(\"Train accuracy:\", train_accuracy.result())\n",
    "            \n",
    "            # We evaluate the test set every 10 epochs to avoid computational overhead\n",
    "            for (minibatch_X, minibatch_Y) in test_minibatches:\n",
    "                Z3 = forward_propagation(tf.transpose(minibatch_X), parameters)\n",
    "                test_accuracy.update_state(tf.transpose(Z3), minibatch_Y)\n",
    "            print(\"Test_accuracy:\", test_accuracy.result())\n",
    "\n",
    "            costs.append(epoch_cost)\n",
    "            train_acc.append(train_accuracy.result())\n",
    "            test_acc.append(test_accuracy.result())\n",
    "            test_accuracy.reset_states()\n",
    "\n",
    "\n",
    "    return parameters, costs, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.057808\n",
      "Train accuracy: tf.Tensor(0.17685185, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.19166666, shape=(), dtype=float32)\n",
      "Cost after epoch 10: 0.048614\n",
      "Train accuracy: tf.Tensor(0.40555555, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.49166667, shape=(), dtype=float32)\n",
      "Cost after epoch 20: 0.042072\n",
      "Train accuracy: tf.Tensor(0.5574074, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.55833334, shape=(), dtype=float32)\n",
      "Cost after epoch 30: 0.038114\n",
      "Train accuracy: tf.Tensor(0.61944443, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.56666666, shape=(), dtype=float32)\n",
      "Cost after epoch 40: 0.035045\n",
      "Train accuracy: tf.Tensor(0.6638889, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.575, shape=(), dtype=float32)\n",
      "Cost after epoch 50: 0.032562\n",
      "Train accuracy: tf.Tensor(0.68333334, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.6166667, shape=(), dtype=float32)\n",
      "Cost after epoch 60: 0.030359\n",
      "Train accuracy: tf.Tensor(0.7287037, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.625, shape=(), dtype=float32)\n",
      "Cost after epoch 70: 0.028136\n",
      "Train accuracy: tf.Tensor(0.7592593, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.6333333, shape=(), dtype=float32)\n",
      "Cost after epoch 80: 0.026263\n",
      "Train accuracy: tf.Tensor(0.78518516, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.6666667, shape=(), dtype=float32)\n",
      "Cost after epoch 90: 0.024529\n",
      "Train accuracy: tf.Tensor(0.80925924, shape=(), dtype=float32)\n",
      "Test_accuracy: tf.Tensor(0.65833336, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "parameters,costs,train_acc,test_acc=model(new_train,new_y_train,new_test,new_y_test,num_epochs=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
